title: Framework per Big Data
subtitle: Hadoop e (Py)Spark
figure: images/db/overflow.png

---

title: Volume and velocity

- Big Data often characterized in terms of 5 Vs (+ others)
    - Volume, variety, velocity, value, veracity
- Challenges to traditional computational architectures
    - Handle large quantities of data (*volume*)
    - Readily react to their arrival (*velocity*)

---

title: A meta-definition

> Big data should be defined at any point in time as «data whose size forces us to look beyond the tried-and-true methods that are prevalent at that time.» *(Jacobs, 2009)*

- Meta-definition centered on *volume*
    - It ignores other Vs
- *Moving threshold*, for a dataset to be defined as “big data”
    - It grows together with technological advances

---

title: Big data pathologies

- Transaction processing and data storage are largely solved problems
- Data with a traditional RDBMS
    - Easier to *get in* than *get out*
    - Worst pathologies are related to **data analysis**

---

title: How much data?

- Nowadays, a dataset is “big”, if
    - It cannot be loaded and processed effectively with desktop tools for data analys and visualization
- Ex.: dataset of 7 billion records (Jacob, 2009)
- It can be saved in a common HDD
    - Simple questions (min, max, avg) can be answered quickly, by reading the file sequentially
    - More complex queries are difficult
- With some effort, it can be loaded in a RDMBS
    - Analysis through SQL queries is way too slow

---

title: Bounded Dataset vs Unbounded Dataset

Bounded Dataset:
-- Un insieme finito di dati disponibili tutti qui ed ora
Unbounded Dataset:
-- Dati in continuo arrivo
-- Spesso associati alla parola "streaming"

---

title: Unbounded Dataset -- 2 domini temporali

Un unbounded dataset è caratterizzato da due domini temporali:
-- Tempo dell'evento: istante in cui l'evento descritto da un dato è
effettivamente occorso
-- Tempo dell'elaborazione: istante in cui il dato entra all'interno del
sistema di elaborazione
Spesso c'è una differenza non costante tra i due, chiamata skew.
Quando si è interessati a ragionare sul tempo dell'evento, lo skew
può complicare la generazione di risultati corretti.

---

title: Elaborazione di bounded dataset

I bounded dataset sono generalmente elaborati con
sistemi di tipo batch:
-- MapReduce ne è un esempio

---

title: Elaborazione di unbounded dataset

Un dataset unbound può essere elaborato in vari modi:
-- Batch
-- Streaming

---

title: Elaborazione di unbounded dataset - batch

I dati sono bufferizzati (secondo una logica di
windowing) creando una sorta di bounded dataset, che
può essere elaborato con un sistema di tipo batch:
-- Se l'event time è rilevante, allora abbiamo possibili
problemi di incompletezza
-- L'analisi di una sessione utente potrebbe essere suddivisa
tra più batch (se la sessione dura più della finestra)

---

title: Elaborazione di unbounded dataset -

streaming
Ci sono diversi approcci di elaborazione streaming:
- Time-agnostic
- Approximation
- Windowing by processing time
- Windowing by event time

---

title: Elaborazione di unbounded dataset -- streaming -- time agnostic

L'elaborazione di stream quando il tempo non
interessa:
-- Filtrare i dati
-- Calcolare la join di due dataset. Un dato è bufferizzato
finché non arriva un messaggio corrispondente. Tuttavia,
se questo messaggio potesse non esistere, occorrerebbe
inserire un timeout, quindi una nozione di tempo

---

title: Elaborazione di unbounded dataset -- streaming -- widowing

Posso suddividere i dati in ingresso in finestre (fisse,
scorrevoli o sessioni) secondo il processing time o l'event
time:
Nel secondo caso è difficile giudicare la completezza di una
finestra:
- Ci si può basare su delle euristiche
- Oppure, chiedere all'"esterno" quando i dati vanno materializzati
- Procedure per raffinare i dati nel tempo

---

title: Free lunch is over

- For a long time, programs have taken advantage from growing hardware performances
- Limits to Moore's law
    - Physical limits make it hard to increase the transistor density
    - Heat dissipation make it hard to increase frequency
- The free lunch is over (Sutter, 2004)
    - Multi-core processors
    - Multi-threaded programs to exploit hardware parallelism
- Concurrent programming is hard
    - Deadlock, livelock, starvation, race, etc.
    - Some algorithms are intrinsically sequential

---

title: Amdahl's law

- A limit to program speedup (how much it is faster on a parallel hardware)
    - *T~~1~~ = T~~ser~~ + T~~par~~*
    - *f = T~~ser~~/T~~1~~*
    - *T~~P~~ ≥ T~~ser~~ + T~~par~~/P = fT~~1~~ + (1−f)T~~1~~/P*
    - *S~~P~~ = T~~1~~/T~~P~~ ≤ T~~1~~/(fT~~1~~ + (1−f)T~~1~~/P) = 1/(f + (1−f)/P)*
    - *S~~∞~~ ≤ lim~~P→∞~~ 1/(f + (1−f)/P) = 1/f*
- *f*: fraction of work which is sequential
- A program spending 1% of its execution time on a sequential task
    - Speedup limited to max 100 times faster, with unlimited parallelism

---

title: Distributed systems

- Limited resources on a single node -> more nodes
- Additional problems, wrt parallel systems
    - Is a node dead or very slow?
    - Is a task being executed?
    - How to reach consensus?
- Framework for distributed computing
    - Fault tolerance
    - Data distribution
    - Parallelization
    - Load balancing

---

title: MapReduce

- Introduced by Google for indexing the web etc.
- Inspired by `map` and `reduce` functions in Lisp
- Functional approach
    - Higher level functions
    - Immutable data -> independent execution
    - Redundance for fault tolerance

---

title: MapReduce basics

- *Input*: a collection of pairs `(K~~1~~, V~~1~~)`
- *Output*: `(K~~2~~, V~~2~~)`
- `map`
    - For each input pair, it generates a list of intermediate pairs
    - Each intermediate key associated with multiple values
- `reduce`
    - For each intermediate key, it aggregates all the corresponding values into a final result

---

title: MapReduce example

code: py

    def map(key: str, value: str):
        # key: document name
        # value: document contents
        counts = dict()
        for w in value.split():
            counts[w] = 1 + counts.get(w, 0)
        emit_intermediate(counts)

    reduce(key: str, values: list):
        # key: a word
        # values: a list of counts
        result = 0
        for v in values:
            result += v
        emit(result)

---

title: MapReduce -- esempio (2/2) [26]

(the, 1)
the cat
the dog
a cat
a dog
(cat, 1) (a, 1)
(the, 1) (cat, 1)
(dog, 1) (cat, 1)
(a, 1) (dog, 1)
(cat, 1)
(a, 1)
(dog, 1)

(a, 1)
(a, 2)
(cat, 2)
(dog, 2)
(dog, 1)
(the, 1)
(the, 2)
(the, 1)

---

title: MapReduce -- map task

Se map è una funzione pura, può essere eseguita in
parallelo su porzioni differenti dell'input.
Da ciò l'idea di suddividere l'input in tanti blocchi (di
64MB)
ciascuno dei quali è un map task, che può essere
assegnato (scheduled) su uno dei nodi worker.
Solitamente il numero di map task viene indicato con
M.

---

title: MapReduce -- reduce task

Per quanto riguarda la funzione reduce, lo spazio delle
chiavi intermedie viene partizionato.
Ciascuna partizione diventa un reduce task, che può
essere assegnato (scheduled) su uno dei nodi worker.
Se R è il numero di reduce task, una funzione di
partizionamento può essere: hash(k 2 ) mod R

---

title: MapReduce -- DFS (1)

Il computing model MapReduce è abbinato ad un filesystem
distribuito (DFS):
-- Ciascun file di input è suddiviso in blocchi di dimensione fissa
-- Ciascun blocco viene immagazzinato su un data node e la
posizione dei diversi blocchi è immagazzinata su un name node
(responsabile del namespace)
-- Fault tolerance (rispetto ai guasti dei data node) ottenuta
replicando ciascun blocco su un numero (stabilito) di data node
(secondo varie policy)

---

title: MapReduce -- DFS (2)

Come si combinano MapReduce e DFS?
-- Si cerca di assegnare a ciascun worker map task relativi a blocchi
che sono replicati su quella macchina (località)
-- Il woker responsabile di un map task scriverà le chiavi
intermedie su tanti file nel proprio file system locale quanti
sono i reduce task
-- Ciascun reduce task chieve legge (tramite RPC) il contenuto del
filesystem locale di ciascun mapper, e produce un file nel DFS
(ordinato per chiave) con
11/12/2018
il risultato del proprio lavoro.

---

title: MapReduce -- esecuzione [31]

---

title: MapReduce -- fault tolerance

Se un worker fallisce:
- map task completati sono rieseguiti, perché il loro
output non è più accessibile (si trova nel filesyste locale)
- reduce task completati non sono rieseguiti, perché il
loro output è stato salvato nel DFS (quindi i blocchi si
trovano, possibilmente replicati, su altri nodi)

---

title: MapReduce -- alcune ottimizzazioni

combiner:
-- Effettuano una riduzione parziale localmente a ciascun map task.
In molti casi, il combiner è banalmente il reducer.
backup task:
-- Talvolta un task può richiedere molto più tempo del previsto
(per diversi ragioni): quando il processo di MapReduce è
prossimo al completamento, il master avvia delle copie di
backup dei task ancora running, per evitare che il processo sia
rallentato da questi task che sono più lenti del normale.

---

title: MapReduce -- algoritmi iterativi

MapReduce non è particolarmente indicato per
implementare algoritmi iterativi su grafi:
-- Occorre gestire (fuori dal framework) una sequenza di job
MapReduce (sconvenienza)
-- La natura funzionale del modello computazione ci costringe
spesso a copiare l'intero grafo da un'iterazione all'altra
(inefficienza)

---

title: Apache Hadoop

L'implementazione di MapReduce fatta da Google è
proprietaria, ed usata internamente dal motore di ricerca di
Mountain View.
Gli altri possono usare il "clone open-source" Apache
Hadoop.
http://hadoop.apache.org/

---

title: Apache Hadoop 2

Nella versione 2, l'introduzione di YARN per la gestione del cluster, ha permesso ad
Hadoop di svincolarsi da MapReduce (quale unico programming model)
https://it.hortonworks.com/blog/apache-hadoop-2-is-ga/

---

title: HDFS - Assunzioni

Hadoop Distributed Filesystem (HDFS) è il filesystem distribuito alla base di Apache
Hadoop.
Principali assunzioni:
- Hardware failure: tolleranza ai guasti implementata al livello applicativo
(principalmente attraverso la replicazione dei blocchi di dati)
- Streaming Data Access: orientato alle applicazioni batch, piuttosto che all'uso
interattivo. Favorisce il throughput alla latency
- Large Data Sets: decine di milioni di file da GB a TB. Scalabilità a centinaia di nodi
- Simple Coherency Model: una volta che un file è stato chiuso, è solo possibile
appendervi del contenuto oppure troncarlo
- "Moving Computation is Cheaper than Moving Data": HDFS fornisce delle
interfacce che permettono alle applicazioni di spostarsi vicino a dove i dati sono
effettivamente immagazzinati
- Portability across Heterogeneous Hardware and Software Platforms

---

title: HDFS - Architettura

http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html

---

title: HDFS - Cartoon

https://wiki.scc.kit.edu/gridkaschool/upload/1/18/Hdfs-cartoon.pdf

---

title: YARN - Architettura

https://developer.ibm.com/tutorials/bd-yarn-intro/

---

title: HDFS -- Assunzioni

Hadoop Distributed Filesystem (HDFS) è il filesystem distribuito alla base di Apache
Hadoop.
Principali assunzioni:
- Hardware failure: tolleranza ai guasti implementata al livello applicativo
(principalmente attraverso la replicazione dei blocchi di dati)
- Streaming Data Access: orientato alle applicazioni batch, piuttosto che l'uso
interattivo. Favorisce il throughput alla latency
- Large Data Sets: decine di milioni di file da GB a TB. Scalabilità a centinaia di nodi
- Simple Coherency Model: una volta che un file è stato chiuso, è solo possibile
appendervi del contenuto oppure troncarlo
- "Moving Computation is Cheaper than Moving Data": HDFS fornisce delle
interfacce che permettono alle applicazioni di spostarsi vicino a dove i dati sono
effettivamente immagazzinati
- Portability across Heterogeneous Hardware and Software Platforms

---

title: Hadoop -- Modailità d'uso

- Modalità locale (standalone) [default]
-- Eseguito come un singolo processo Java
-- Utile per il debugging
- Modalità pseudodistribuita
-- Eseguito come un insieme di processi (NameNode, DataNode,
Secondary NameNode, ResourceManager, NodeManager,
WebAppProxy and Map Reduce Job History Server) su una singola
macchina
- Modalità pienamente distribuita
-- I vari processi elencati in precedenza sono distribuiti su più macchine


---

title: Hadoop MapReduce -- InputFormat

Un InputFormat describe la specifica di input per un job
MapReduce.
Il framework MapReduce si affida all'InputFormat del job per:
- Validare la specifica del'input del job.
- Suddividere i file di in istanze di InputSplit, ciascuna delle
quali è assegnato ad un Mapper invididuale.
- Fornire l'implementazione del RecordReader per estrarre
dall'InputSplit i record che saranno elaborate dal Mapper.


---

title: Hadoop MapReduce -- InputSplit

InputSplit rappresenta i dati che devono essere elaborati da un
certo Mapper.
Tipicamente InputSplit presenta un visione dell'input orientata ai
byte, ed è responsabilità del RecordReader elaborarla e
presentare una visione a record.
FileSplit è l'InputSplit predefinito. Esso setta
mapreduce.map.input.file al path del file di input dello split logico.


---

title: Hadoop MapReduce -- RecordReader

Un RecordReader legge coppie <key, value> da un InputSplit.
Tipicamente un RecordReader converte la visione dell'input
orientata ai byte, fornita da un InputSplit, e presenta una
visione a record alle implementazioni di Mapper per
l'elaborazione. Il RecordReader assume pertanto la
responsabilità di elaborare i confini dei record e presentare
ai task chiavi e valori.


---

title: Hadoop MapReduce -- OutputFormat

OutputFormat descrive la specifica di output per un job
MapReduce.
Il framework MapReduce si affida all'OutputFormat del job per:
- Validare la specifica di output del job; per esempio,
controllare la cartella di output non esista già.
- Fornire l'implementazione di RecordWriter usata per scrivere i
file di output del job. I file di output solo immagazzinati in un
FileSystem.
TextOutputFormat è l'OutputFormat predefinito.


---

title: Hadoop MapReduce -- Counter

I counters rappresentano contatori globali, definiti dal
framework MapReduce o dalle applicazioni. Ogni
Counter può essere di qualunque tipo Enum. Contatori
di un particolare Enum sono messi insieme in gruppi di
tipo Counters.Group.

---

title: Hadoop MapReduce -- SkipBadRecords

Hadoop fornisce un'opzione dove un certo insieme di
input record cattivi può essere saltato durante la fase di
map. Le applicazioni possono controllare questa feature
attraverso la classe SkipBadRecords.


---

title: Hadoop MapReduce -- input/output multipli

La classe MultipleInputs supporta job MapReduce con più
input path aventi ciascuno un InputFormat e Mapper diversi.
https://hadoop.apache.org/docs/r2.9.2/api/org/apache/hadoo
p/mapreduce/lib/input/MultipleInputs.html
La classe MultipleOutputs semplifica la scrittura su più file di
output.
https://hadoop.apache.org/docs/r2.9.2/api/org/apache/hadoo
p/mapreduce/lib/output/MultipleOutputs.html

---

title: Hadoop MapReduce -- lib
Nel package org.apache.hadoop.mapreduce.lib si trova
una libreria di classi di interesse.

--

title: Hadoop MapReduce -- scrivere soltanto i valori

Per scrivere soltanto I valori si può usare NullWritable
come tipo di output.

---

title: Hadoop -- Modalità locale (default)

Comandi per shell Unix. Per la PowerShell di Windows è sufficiente usare il
backslash
Esegue un JAR.
$ mkdir input
$ cp etc/hadoop/*.xml input
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-
2.9.2.jar grep input output 'dfs[a-z.]+'
$ cat output/*

---

