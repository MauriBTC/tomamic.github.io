title: Framework per Big Data
subtitle: Hadoop e (Py)Spark
figure: images/db/overflow.png

---

title: Volume and velocity

- Big Data often characterized in terms of 5 Vs (+ others)
    - Volume, variety, velocity, value, veracity
- Challenges to traditional computational architectures
    - Handle large quantities of data (*volume*)
    - Readily react to their arrival (*velocity*)

---

title: A meta-definition

> Big data should be defined at any point in time as «data whose size forces us to look beyond the tried-and-true methods that are prevalent at that time.» *(Jacobs, 2009)*

- Meta-definition centered on *volume*
    - It ignores other Vs
- *Moving threshold*, for a dataset to be defined as “big data”
    - It grows together with technological advances

---

title: Big data pathologies

- Transaction processing and data storage are largely solved problems
- Data with a traditional RDBMS
    - Easier to *get in* than *get out*
    - Worst pathologies are related to **data analysis**

---

title: How much data?

- Nowadays, a dataset is “big”, if
    - It cannot be loaded and processed effectively with desktop tools for data analys and visualization
- Ex.: dataset of 7 billion records (Jacob, 2009)
- It can be saved in a common HDD
    - Simple questions (min, max, avg) can be answered quickly, by reading the file sequentially
    - More complex queries are difficult
- With some effort, it can be loaded in a RDMBS
    - Analysis through SQL queries is way too slow

---

title: Bounded Dataset vs Unbounded Dataset

- Bounded Dataset
	- A finite set of data, already available at the start
- Unbounded Dataset
	- Data arriving continuously
	- Often in a “streaming” scenario

---

title: Unbounded Dataset -- 2 domini temporali

- Unbounded dataset characterized by two temporal domains
	- Event time: when the event occurs
	- Computation time: when data enter the processing system
- Often, non-constant difference between them: skew
- When the event time is important, skew can complicate the generation of correct results

---

title: Processing of bounded / unbounded dataset

- Bounded datasets
	- Often processed with batch systems; e.g. MapReduce
- Unbounded datasets
	- Processed in either batch or streaming mode
	- Data buffered in a windowing logic
	- Sort of bounded dataset, processed as batch
	- Incomplete data, if event time is important
	- A user session can be divided in multiple batches, if longer than a window
	
---

title: Free lunch is over

- For a long time, programs have taken advantage from growing hardware performances
- Limits to Moore's law
    - Physical limits make it hard to increase the transistor density
    - Heat dissipation make it hard to increase frequency
- The free lunch is over (Sutter, 2004)
    - Multi-core processors
    - Multi-threaded programs to exploit hardware parallelism
- Concurrent programming is hard
    - Deadlock, livelock, starvation, race, etc.
    - Some algorithms are intrinsically sequential

---

title: Amdahl's law

- A limit to program speedup (how much it is faster on a parallel hardware)
    - *T~~1~~ = T~~ser~~ + T~~par~~*
    - *f = T~~ser~~/T~~1~~*
    - *T~~P~~ ≥ T~~ser~~ + T~~par~~/P = fT~~1~~ + (1−f)T~~1~~/P*
    - *S~~P~~ = T~~1~~/T~~P~~ ≤ T~~1~~/(fT~~1~~ + (1−f)T~~1~~/P) = 1/(f + (1−f)/P)*
    - *S~~∞~~ ≤ lim~~P→∞~~ 1/(f + (1−f)/P) = 1/f*
- *f*: fraction of work which is sequential
- A program spending 1% of its execution time on a sequential task
    - Speedup limited to max 100 times faster, with unlimited parallelism

---

title: Distributed systems

- Limited resources on a single node -> more nodes
- Additional problems, wrt parallel systems
    - Is a node dead or very slow?
    - Is a task being executed?
    - How to reach consensus?
- Framework for distributed computing
    - Fault tolerance
    - Data distribution
    - Parallelization
    - Load balancing

---

title: MapReduce

- Introduced by Google for indexing the web etc.
- Inspired by `map` and `reduce` functions in Lisp
- Functional approach
    - Higher level functions
    - Immutable data -> independent execution
    - Redundance for fault tolerance

---

title: MapReduce basics

- *Input*: a collection of pairs `(K~~1~~, V~~1~~)`
- *Output*: `(K~~2~~, V~~2~~)`
- `map`
    - For each input pair, it generates a list of intermediate pairs
    - Each intermediate key associated with multiple values
- `reduce`
    - For each intermediate key, it aggregates all the corresponding values into a final result

---

title: MapReduce, pseudo-code

code: py

	def map_f(filename: str) -> [(str, int)]:
    	counts = {}
    	with open(filename) as f:
        	for word in f.read().split():
            	counts[word] = 1 + counts.get(word, 0)
    	return list(counts.items())
	
	def reduce_f(item: (str, [int])) -> (str, int):
    	key, values = item  # key: a word; values: a list of counts
    	return key, sum(values)
	
---

title: MapReduce, simplistic framework

code: py

	def partition(interm: [(str, int)]) -> [(str, [int])]:
    	# interm: results of map phase, chained together
    	counts = {}
    	for key, val in interm:
        	if key in counts:
            	counts[key].append(val)
        	else:
            	counts[key] = [val]
    	return list(counts.items())
	
	def main():
    	pool = multiprocessing.Pool(8)  # num_workers
    	input_list = glob.glob("*.txt")
    	map_responses = pool.map(map_f, input_list)
    	chained = sum(map_responses, [])
    	partitioned_data = partition(chained)
    	reduced_values = pool.map(reduce_f, partitioned_data)
    	print(list(reduced_values))
	
---

title: MapReduce -- esempio (2/2) [26]

(the, 1)
the cat
the dog
a cat
a dog
(cat, 1) (a, 1)
(the, 1) (cat, 1)
(dog, 1) (cat, 1)
(a, 1) (dog, 1)
(cat, 1)
(a, 1)
(dog, 1)

(a, 1)
(a, 2)
(cat, 2)
(dog, 2)
(dog, 1)
(the, 1)
(the, 2)
(the, 1)

---

title: MapReduce -- map task

- If `map` is a pure function, it can run in parallel on multiple parts of the input
- Input is divided into many blocks (e.g. of 64MB)
- Each assigned to a worker node
- Number of map tasks usually called `M`

---

title: MapReduce -- reduce task

- The space of intermediate keys is partitioned, before applying `reduce`
- Each part is a `reduce` task, assigned to a worker node
- Numer of reduce tasks: `R`
- E.g. partitioning policy: `hash(k2) mod R`

---

title: MapReduce -- DFS (1)

- Computing model of MapReduce associated with distributed filesystem (DFS)
- Each input file divided into blocks of fixed size
- Each block stored on (more than) a data node
	- Their position stored on a name node (responsible for the namespace)
- Various replication policies of blocks on data nodes
	- Fault tolerance (wrt failures of data nodes) and efficiency

---

title: MapReduce -- DFS (2)

- How do MapReduce and DFS combine?
- Each worker is assigned a map task for blocks replicated on that machine (locality)
- Assigned worker writes intermediate keys in its own local node of the DFS
- As many intermediate files, as reduce tasks
- Each reduce task reads from the DFS of each mapper
- It produces a file in local node of DFS, with its own results

---

title: MapReduce -- esecuzione [31]

---

title: MapReduce -- fault tolerance

Se un worker fallisce:
- map task completati sono rieseguiti, perché il loro
output non è più accessibile (si trova nel filesyste locale)
- reduce task completati non sono rieseguiti, perché il
loro output è stato salvato nel DFS (quindi i blocchi si
trovano, possibilmente replicati, su altri nodi)

---

title: MapReduce -- alcune ottimizzazioni

combiner:
-- Effettuano una riduzione parziale localmente a ciascun map task.
In molti casi, il combiner è banalmente il reducer.
backup task:
-- Talvolta un task può richiedere molto più tempo del previsto
(per diversi ragioni): quando il processo di MapReduce è
prossimo al completamento, il master avvia delle copie di
backup dei task ancora running, per evitare che il processo sia
rallentato da questi task che sono più lenti del normale.

---

title: MapReduce -- algoritmi iterativi

MapReduce non è particolarmente indicato per
implementare algoritmi iterativi su grafi:
-- Occorre gestire (fuori dal framework) una sequenza di job
MapReduce (sconvenienza)
-- La natura funzionale del modello computazione ci costringe
spesso a copiare l'intero grafo da un'iterazione all'altra
(inefficienza)

---

title: Apache Hadoop

L'implementazione di MapReduce fatta da Google è
proprietaria, ed usata internamente dal motore di ricerca di
Mountain View.
Gli altri possono usare il "clone open-source" Apache
Hadoop.
http://hadoop.apache.org/

---

title: Apache Hadoop 2

Nella versione 2, l'introduzione di YARN per la gestione del cluster, ha permesso ad
Hadoop di svincolarsi da MapReduce (quale unico programming model)
https://it.hortonworks.com/blog/apache-hadoop-2-is-ga/

---

title: HDFS - Assunzioni

Hadoop Distributed Filesystem (HDFS) è il filesystem distribuito alla base di Apache
Hadoop.
Principali assunzioni:
- Hardware failure: tolleranza ai guasti implementata al livello applicativo
(principalmente attraverso la replicazione dei blocchi di dati)
- Streaming Data Access: orientato alle applicazioni batch, piuttosto che all'uso
interattivo. Favorisce il throughput alla latency
- Large Data Sets: decine di milioni di file da GB a TB. Scalabilità a centinaia di nodi
- Simple Coherency Model: una volta che un file è stato chiuso, è solo possibile
appendervi del contenuto oppure troncarlo
- "Moving Computation is Cheaper than Moving Data": HDFS fornisce delle
interfacce che permettono alle applicazioni di spostarsi vicino a dove i dati sono
effettivamente immagazzinati
- Portability across Heterogeneous Hardware and Software Platforms

---

title: HDFS - Architettura

http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html

---

title: HDFS - Cartoon

https://wiki.scc.kit.edu/gridkaschool/upload/1/18/Hdfs-cartoon.pdf

---

title: YARN - Architettura

https://developer.ibm.com/tutorials/bd-yarn-intro/

---

title: HDFS -- Assunzioni

Hadoop Distributed Filesystem (HDFS) è il filesystem distribuito alla base di Apache
Hadoop.
Principali assunzioni:
- Hardware failure: tolleranza ai guasti implementata al livello applicativo
(principalmente attraverso la replicazione dei blocchi di dati)
- Streaming Data Access: orientato alle applicazioni batch, piuttosto che l'uso
interattivo. Favorisce il throughput alla latency
- Large Data Sets: decine di milioni di file da GB a TB. Scalabilità a centinaia di nodi
- Simple Coherency Model: una volta che un file è stato chiuso, è solo possibile
appendervi del contenuto oppure troncarlo
- "Moving Computation is Cheaper than Moving Data": HDFS fornisce delle
interfacce che permettono alle applicazioni di spostarsi vicino a dove i dati sono
effettivamente immagazzinati
- Portability across Heterogeneous Hardware and Software Platforms

---

title: Hadoop -- Modailità d'uso

- Modalità locale (standalone) [default]
-- Eseguito come un singolo processo Java
-- Utile per il debugging
- Modalità pseudodistribuita
-- Eseguito come un insieme di processi (NameNode, DataNode,
Secondary NameNode, ResourceManager, NodeManager,
WebAppProxy and Map Reduce Job History Server) su una singola
macchina
- Modalità pienamente distribuita
-- I vari processi elencati in precedenza sono distribuiti su più macchine


---

title: Hadoop MapReduce -- InputFormat

Un InputFormat describe la specifica di input per un job
MapReduce.
Il framework MapReduce si affida all'InputFormat del job per:
- Validare la specifica del'input del job.
- Suddividere i file di in istanze di InputSplit, ciascuna delle
quali è assegnato ad un Mapper invididuale.
- Fornire l'implementazione del RecordReader per estrarre
dall'InputSplit i record che saranno elaborate dal Mapper.


---

title: Hadoop MapReduce -- InputSplit

InputSplit rappresenta i dati che devono essere elaborati da un
certo Mapper.
Tipicamente InputSplit presenta un visione dell'input orientata ai
byte, ed è responsabilità del RecordReader elaborarla e
presentare una visione a record.
FileSplit è l'InputSplit predefinito. Esso setta
mapreduce.map.input.file al path del file di input dello split logico.


---

title: Hadoop MapReduce -- RecordReader

Un RecordReader legge coppie <key, value> da un InputSplit.
Tipicamente un RecordReader converte la visione dell'input
orientata ai byte, fornita da un InputSplit, e presenta una
visione a record alle implementazioni di Mapper per
l'elaborazione. Il RecordReader assume pertanto la
responsabilità di elaborare i confini dei record e presentare
ai task chiavi e valori.


---

title: Hadoop MapReduce -- OutputFormat

OutputFormat descrive la specifica di output per un job
MapReduce.
Il framework MapReduce si affida all'OutputFormat del job per:
- Validare la specifica di output del job; per esempio,
controllare la cartella di output non esista già.
- Fornire l'implementazione di RecordWriter usata per scrivere i
file di output del job. I file di output solo immagazzinati in un
FileSystem.
TextOutputFormat è l'OutputFormat predefinito.


---

title: Hadoop MapReduce -- Counter

I counters rappresentano contatori globali, definiti dal
framework MapReduce o dalle applicazioni. Ogni
Counter può essere di qualunque tipo Enum. Contatori
di un particolare Enum sono messi insieme in gruppi di
tipo Counters.Group.

---

title: Hadoop MapReduce -- SkipBadRecords

Hadoop fornisce un'opzione dove un certo insieme di
input record cattivi può essere saltato durante la fase di
map. Le applicazioni possono controllare questa feature
attraverso la classe SkipBadRecords.


---

title: Hadoop MapReduce -- input/output multipli

La classe MultipleInputs supporta job MapReduce con più
input path aventi ciascuno un InputFormat e Mapper diversi.
https://hadoop.apache.org/docs/r2.9.2/api/org/apache/hadoo
p/mapreduce/lib/input/MultipleInputs.html
La classe MultipleOutputs semplifica la scrittura su più file di
output.
https://hadoop.apache.org/docs/r2.9.2/api/org/apache/hadoo
p/mapreduce/lib/output/MultipleOutputs.html

---

title: Hadoop MapReduce -- lib
Nel package org.apache.hadoop.mapreduce.lib si trova
una libreria di classi di interesse.

--

title: Hadoop MapReduce -- scrivere soltanto i valori

Per scrivere soltanto I valori si può usare NullWritable
come tipo di output.

---

title: Hadoop -- Modalità locale (default)

Comandi per shell Unix. Per la PowerShell di Windows è sufficiente usare il
backslash
Esegue un JAR.
$ mkdir input
$ cp etc/hadoop/*.xml input
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-
2.9.2.jar grep input output 'dfs[a-z.]+'
$ cat output/*

---

